{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2c439f",
   "metadata": {},
   "source": [
    "## Data Security & Privacy in Workflows: Spark Solutions\n",
    "\n",
    "In this notebook, you'll find solutions as to one way to solve the translation between Python processing and Spark. Remember: there are usually multiple ways to solve a problem in Spark! So long as yours worked, please take these as simply suggestions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df5e8c",
   "metadata": {},
   "source": [
    "### Our Goal: Build a Privacy-First Sensor Map\n",
    "\n",
    "- We want to ingest air quality sensor data from users, buildings and institutions who are willing to send us data to build an air quality map (similar to the [IQAir map](https://www.iqair.com/air-quality-map).\n",
    "- Users only want to share the data if they can remain anonymous and their location is fuzzy, so that they are protected against stalkers, prying eyes and state surveillance.\n",
    "- Since the data is sensitive (from people and their homes!), we want to sure that it is secured either at collection, as well as at any intermediary hops.\n",
    "\n",
    "Let's first take a look at our data and determine what can and should be done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01affb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, TimestampType\n",
    "from pyspark.sql.functions import when, split, udf, round as pys_round,\\\n",
    "    regexp_replace, rand, to_timestamp, expr, unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00911d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"data/air_quality.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38296d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('location').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c69fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"location\", regexp_replace(\"location\", \"[()']\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('location').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266979f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"location_arr\", split(\"location\", \", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514558e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c092fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('lat', df.location_arr.getItem(0).cast('float'))\n",
    "df = df.withColumn('long', df.location_arr.getItem(1).cast('float'))\n",
    "df = df.withColumn('city', df.location_arr.getItem(2))\n",
    "df = df.withColumn('country', df.location_arr.getItem(3))\n",
    "df = df.withColumn('timezone', df.location_arr.getItem(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342db90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.drop('location', 'location_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c236d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae8e78",
   "metadata": {},
   "source": [
    "What else is missing for our map? It seems like on IQAir's map they have categories of pollutants. We likely want to do something similar to break our map down into colors and ranges. \n",
    "\n",
    "Based on the IQAir map, the ranges look to be about:\n",
    "\n",
    "- Great: less than or equal to 50\n",
    "- Good: 51-100\n",
    "- Okay: 101-150\n",
    "- Poor: 151-200\n",
    "- Bad: 201-300\n",
    "- Extremely Bad: 301+\n",
    "\n",
    "Let's make these into integer values 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.withColumn('air_quality_category', when(\n",
    "    cleaned_df.air_quality_index <= 50, 1).when(\n",
    "    cleaned_df.air_quality_index <= 100, 2).when(\n",
    "    cleaned_df.air_quality_index <= 150, 3).when(\n",
    "    cleaned_df.air_quality_index <= 200, 4).when(\n",
    "    cleaned_df.air_quality_index <= 300, 5).otherwise(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a391098",
   "metadata": {},
   "source": [
    "#### What is sensitive here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eae1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.sample(0.01).show(3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d7d46",
   "metadata": {},
   "source": [
    "#### How might we...?\n",
    "\n",
    "- Protect user_id while still allowing it to be linkable?\n",
    "- Remove potentially identifying precision in location?\n",
    "- Remove potentially identifying information in the timestamp?\n",
    "- Make these into scalable and repeatable actions for our workflow?\n",
    "\n",
    "Let's work on these step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac236a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ff3 import FF3Cipher\n",
    "key = \"2DE79D232DF5585D68CE47882AE256D6\"\n",
    "tweak = \"CBD09280979564\"\n",
    "\n",
    "c6 = FF3Cipher.withCustomAlphabet(key, tweak, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_\")\n",
    "\n",
    "plaintext = \"michael______\"\n",
    "ciphertext = c6.encrypt(plaintext)\n",
    "\n",
    "ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c212c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted = c6.decrypt(ciphertext)\n",
    "decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a55ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_username(username):\n",
    "    c6 = FF3Cipher.withCustomAlphabet(key, tweak, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_\")\n",
    "    return c6.encrypt(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypt_username_udf = udf(lambda z: encrypt_username(z), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.select(encrypt_username_udf(\"user_id\").alias(\"user_id\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754519a3",
   "metadata": {},
   "source": [
    "It looks like it's working, but with UDFs you never know. Remember, Spark function evaluation is LAZY, so it will sample a bit and test. To see if it will work on the entire dataframe, we need to call collect. Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.select(encrypt_username_udf(\"user_id\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0d078",
   "metadata": {},
   "source": [
    "Oh no! What happened here???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_and_encrypt(username):\n",
    "    c6 = FF3Cipher.withCustomAlphabet(key, tweak, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_\")\n",
    "    if len(username) < 4:\n",
    "        username += \"X\" * (4-len(username))\n",
    "    return c6.encrypt(username)\n",
    "\n",
    "pad_and_encrypt_username_udf = udf(lambda y: add_padding_and_encrypt(y), StringType())\n",
    "\n",
    "cleaned_df.select(pad_and_encrypt_username_udf(\"user_id\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f030f0",
   "metadata": {},
   "source": [
    "This looks like it works now! Let's add it as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3007882",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.withColumn('user_id', pad_and_encrypt_username_udf(\"user_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e6595",
   "metadata": {},
   "source": [
    "We are now technically leaking length information... which we could determine is okay, so long as access to this data and the real data is fairly controlled. We could also say that we want to by default add padding to every username to make them consistent. This would be a good homework exercise (and also to write a function to decrypt and remove padding!!). One challenge, what happens if my username ends in X??? :) \n",
    "\n",
    "\n",
    "Now we can move onto our GPS data!\n",
    "\n",
    "How precise is GPS data anyways? 🤔 (from [wikipedia](https://en.wikipedia.org/wiki/Decimal_degrees))\n",
    "\n",
    "\n",
    "decimal places  | degrees  |distance\n",
    "------- | -------          |--------\n",
    "0        |1                |111  km\n",
    "1        |0.1              |11.1 km\n",
    "2        |0.01             |1.11 km\n",
    "3        |0.001            |111  m\n",
    "4        |0.0001           |11.1 m\n",
    "5        |0.00001          |1.11 m\n",
    "6        |0.000001         |11.1 cm\n",
    "7        |0.0000001        |1.11 cm\n",
    "8        |0.00000001       |1.11 mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d560511",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.withColumn('lat', pys_round('lat', 3))\n",
    "cleaned_df = cleaned_df.withColumn('long', pys_round('long', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a36c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ab1cf",
   "metadata": {},
   "source": [
    "What type of risk should we be aware of with regard to timestamp precision? When and how do we need to de-risk this  type of information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92738e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.withColumn('timestamp', to_timestamp('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.withColumn('new_timestamp', (unix_timestamp('timestamp') + \n",
    "                                    (rand() * 60) + (rand() * 60 * 20)).cast('timestamp')).select('timestamp', 'new_timestamp').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.withColumn('timestamp', (unix_timestamp('timestamp') + \n",
    "                        (rand() * 60) + (rand() * 60 * 20)).cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df07fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.orderBy(cleaned_df.timestamp.asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/data_for_marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.write.format('csv').save('data/data_for_marketing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420bf6e",
   "metadata": {},
   "source": [
    "### Congratulations!! \n",
    "\n",
    "You've walked through potential privacy snags and helped increase the protection for the individuals sending you their air quality details! Now developers can use this dataset and we have ensured that there are some base protections. As you may have noticed, it wasn't always obvious what we should do -- but by thinking through each data type and determining what worked to balance the utility of the data and the privacy we want to offer, we were able to find some ways to protect individuals. \n",
    "\n",
    "A good set of questions to ask for guidance is:\n",
    "\n",
    "- Where will this data be accessed and used? How safe is this environment?\n",
    "- What person-related data do we actually need to use to deliver this service or product? (data minimization!)\n",
    "- What other protections will be added to this data before it is seen or used? (i.e. encryption at rest, access control systems, or other protections when it reaches another processing point or sink!)\n",
    "- What privacy and security expectations do we want to set for the individuals in this dataset?\n",
    "- Where can we opportunistically add more protection while not hindering the work of data scientists, data analysts, software engineers and other colleagues?\n",
    "\n",
    "\n",
    "As you continue on in your data engineering journey, you'll likely encounter many more situations where you'll need to make privacy and security decisions. If you'd like to learn more and even work as a privacy or security champion -- feel free to join in your organizations' programs to support topics like this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69655c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d14d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
